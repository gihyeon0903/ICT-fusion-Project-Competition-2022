import cv2, os, re, math
import mediapipe as mp
import numpy as np

mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_hands = mp.solutions.hands

from keras.models import load_model
model = load_model('weights/손재활운동손가락사이각도포함.h5')

import socket
import time
from datetime import datetime

HOST = '127.0.0.1' 
PORT = 8000

server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

server_socket.bind((HOST, PORT))

server_socket.listen()

client_socket, addr = server_socket.accept()

print('Connected by', addr)

finger_idx = {
    "Thumb" : [1,2,3,4],
    "Index_Finger" : [5,6,7,8],
    "Middle_Finger" : [9,10,11,12],
    "Ring_Finger" : [13,14,15,16],
    "Pinky" : [17,18,19,20]
}

def deg_cal(landmark_datas):
    theta = np.array([])
    
    # z좌표 없애는 기능
    Z_delete = False
    
    if Z_delete:
        print("z좌표 무시하고 계산")
        k = np.reshape(landmark_datas, (-1,3))
        k = k * (1,1,0)
    
    landmark_datas = np.reshape(landmark_datas, (-1,21,3))
        
    for landmark_data in landmark_datas:
        idx = finger_idx["Thumb"]
        v1 = landmark_data[idx[0]] - landmark_data[idx[1]]
        v2 = landmark_data[idx[2]] - landmark_data[idx[1]]
        v3 = landmark_data[idx[1]] - landmark_data[idx[2]]
        v4 = landmark_data[idx[3]] - landmark_data[idx[2]]       
        
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v3*v4) / ( math.dist(v3,(0,0,0)) * math.dist(v4,(0,0,0)) + 1e-10 ) ) ) )
        
    
        
        idx = finger_idx["Index_Finger"]
        v1 = landmark_data[idx[0]] - landmark_data[idx[1]]
        v2 = landmark_data[idx[2]] - landmark_data[idx[1]]
        v3 = landmark_data[idx[1]] - landmark_data[idx[2]]
        v4 = landmark_data[idx[3]] - landmark_data[idx[2]]       
        
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v3*v4) / ( math.dist(v3,(0,0,0)) * math.dist(v4,(0,0,0)) + 1e-10 ) ) ) )
        
        idx = finger_idx["Middle_Finger"]
        v1 = landmark_data[idx[0]] - landmark_data[idx[1]]
        v2 = landmark_data[idx[2]] - landmark_data[idx[1]]
        v3 = landmark_data[idx[1]] - landmark_data[idx[2]]
        v4 = landmark_data[idx[3]] - landmark_data[idx[2]]       

#         print(np.rad2deg(np.arccos(np.sum(v2 * v1)/math.dist(v1, (0,0,0))*math.dist(v2, (0,0,0)))))
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v3*v4) / ( math.dist(v3,(0,0,0)) * math.dist(v4,(0,0,0)) + 1e-10 ) ) ) )
        
        idx = finger_idx["Ring_Finger"]
        v1 = landmark_data[idx[0]] - landmark_data[idx[1]]
        v2 = landmark_data[idx[2]] - landmark_data[idx[1]]
        v3 = landmark_data[idx[1]] - landmark_data[idx[2]]
        v4 = landmark_data[idx[3]] - landmark_data[idx[2]]           

        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v3*v4) / ( math.dist(v3,(0,0,0)) * math.dist(v4,(0,0,0)) + 1e-10 ) ) ) )
        
        idx = finger_idx["Pinky"]
        v1 = landmark_data[idx[0]] - landmark_data[idx[1]]
        v2 = landmark_data[idx[2]] - landmark_data[idx[1]]
        v3 = landmark_data[idx[1]] - landmark_data[idx[2]]
        v4 = landmark_data[idx[3]] - landmark_data[idx[2]]      
        
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v3*v4) / ( math.dist(v3,(0,0,0)) * math.dist(v4,(0,0,0)) + 1e-10 ) ) ) )
        
        #개별 손가락 사이의 각도 추가!
        v1 = landmark_data[2] - landmark_data[1]
        v2 = landmark_data[6] - landmark_data[5]        
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        
        
        v1 = landmark_data[6] - landmark_data[5]
        v2 = landmark_data[10] - landmark_data[9]        
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )

        v1 = landmark_data[10] - landmark_data[9]
        v2 = landmark_data[14] - landmark_data[13]        
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        
        v1 = landmark_data[14] - landmark_data[13]
        v2 = landmark_data[18] - landmark_data[7]        
        theta = np.append(theta, np.rad2deg(np.arccos(np.sum(v1*v2) / ( math.dist(v1,(0,0,0)) * math.dist(v2,(0,0,0)) + 1e-10 ) ) ) )
        
    return theta.reshape(len(landmark_datas), -1)

cap = cv2.VideoCapture(0)
deg = []
text6 = "start"
gauge = 0

file_list = os.listdir('.\\test_img') # 특정 폴더에 있는 이미지 파일 목록을 불러온다.
img_files = [file for file in file_list if file.endswith('.PNG')]

cnt = len(img_files)
idx = 0

with mp_hands.Hands(
    model_complexity=0,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5) as hands:
    
    while cap.isOpened():
        success, image = cap.read()
        if not success:
            print("Ignoring empty camera frame.")
            continue

        # To improve performance, optionally mark the image as not writeable to
        # pass by reference.
        image.flags.writeable = False
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = hands.process(image)
        
        # Draw the hand annotations on the image.
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        #따라해야하는 예시 사진
        if idx == cnt:
            cv2.destroyAllWindows()
            break        
        test_img = cv2.imread("test_img\\" + img_files[idx])
        test_img = cv2.resize(test_img, dsize=(640, 480), interpolation=cv2.INTER_AREA)
        
        if results.multi_hand_landmarks:
            
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(
                    image,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing_styles.get_default_hand_landmarks_style(),
                    mp_drawing_styles.get_default_hand_connections_style())

            arr = np.array([])
        
            for point in results.multi_hand_landmarks[0].landmark:
                arr = np.append(arr, [round(point.x, 2), round(point.y, 2), round(point.z, 2)])
            arr = np.reshape(arr, (-1,3))
            deg = deg_cal(arr)
            y_prob = model.predict(deg)
            predicted = y_prob.argmax(axis=-1)
            
            if(idx == predicted): gauge += 4
            if(gauge == 100): 
                gauge=0
                idx += 1
            
            text6 = "follow left img : " + str(gauge)+"/100"
            
        # Flip the image horizontally for a selfie-view display.    
        img = cv2.flip(image, 1)
        
        msg = str(img)
        client_socket.sendall(msg.encode())
        
        cv2.putText(img, text6,(0, 40),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),2)
        #img 2개 합쳐서 출력
        img = np.hstack((test_img, img))
        cv2.imshow('MediaPipe Hands', img)
        
        if cv2.waitKey(1) & 0xFF == 27:
            print("close")
            cv2.destroyAllWindows()
            break
        
cap.release()